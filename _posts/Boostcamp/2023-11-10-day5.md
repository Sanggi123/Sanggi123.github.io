---
layout: single
title:  "[week1] day5 확률론 & 통계학 & CNN & RNN"
categories: Level1

---

# 오늘 공부한 내용📝

## 확률론

- 딥러닝은 확률 기반의 기계학습 이론에 바탕을 둔다.

- 회귀 분석에서 L2-노름은 예측오차의 분산을 최소화하는 방향으로 학습

- 분류 문제에서 교차엔트로피는 모델 예측의 불확실성을 최소화하는 방향으로 학습

- 조건부 확률

- 몬테카를로 샘플링 <img title="" src="file:///C:/Users/Ahzic/AppData/Roaming/marktext/images/2023-11-10-15-43-59-image.png" alt="" width="567">
  
  - 데이터를 이용해 기대값을 계산하기위해 사용
  
  - 독립추출만 보장된다면 대수의 법칙에 의해 수렴성 보장



## 통계학

- 모수

- 모수적 방법
  
  - 데이터가 어떤 확률분포를 따른다고 가정하고 분포를 결정하는 모수를 추정하는 방법

- 비모수 방법
  
  - 확률분포를 가정하지 않고 데이터에 따라 모수가 유연하게 바뀔 때 사용

- ex) 정규분포의 모수를 측정
  
  - 표본평균
  
  <img src="file:///C:/Users/Ahzic/AppData/Roaming/marktext/images/2023-11-10-15-56-33-image.png" title="" alt="" width="155">
  
  - 표본분산
  
  <img src="file:///C:/Users/Ahzic/AppData/Roaming/marktext/images/2023-11-10-15-56-57-image.png" title="" alt="" width="238">
  
  이 때 불편 추정량을 구하기 위해 N-1로 나눠준다.
  
  중심극한정리 - 이러한 표집분포는 N이 커질수로 정규분포를 따른다. 모집단이 정규분포가 아니아도 성립

- 최대가능도 추정법(maximum likelihood estimation, MLE)
  
  - 가장 가능성이 높은 모수를 추정하는 방법

# 느낀 점🤔
