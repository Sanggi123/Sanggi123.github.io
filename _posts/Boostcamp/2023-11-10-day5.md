---
layout: single
title:  "[week1] day5 확률론 & 통계학 & CNN & RNN"
categories: Level1

---

# 오늘 공부한 내용📝

## 확률론

- 딥러닝은 확률 기반의 기계학습 이론에 바탕을 둔다.

- 회귀 분석에서 L2-노름은 예측오차의 분산을 최소화하는 방향으로 학습

- 분류 문제에서 교차엔트로피는 모델 예측의 불확실성을 최소화하는 방향으로 학습

- 조건부 확률

- 몬테카를로 샘플링
 ![](../../assets/images/2023-11-10-17-17-38-image.png)
  
  - 데이터를 이용해 기대값을 계산하기위해 사용
  
  - 독립추출만 보장된다면 대수의 법칙에 의해 수렴성 보장

## 통계학

- 모수

- 모수적 방법
  
  - 데이터가 어떤 확률분포를 따른다고 가정하고 분포를 결정하는 모수를 추정하는 방법

- 비모수 방법
  
  - 확률분포를 가정하지 않고 데이터에 따라 모수가 유연하게 바뀔 때 사용

- ex) 정규분포의 모수를 측정
  
  - 표본평균
  
  ![](../../assets/images/2023-11-10-17-18-04-image.png)
  
  - 표본분산
  
  ![](../../assets/images/2023-11-10-17-18-20-image.png)
  
  이 때 불편 추정량을 구하기 위해 N-1로 나눠준다.
  
  중심극한정리 - 이러한 표집분포는 N이 커질수로 정규분포를 따른다. 모집단이 정규분포가 아니아도 성립

- 최대가능도 추정법(maximum likelihood estimation, MLE)
  
  - 가장 가능성이 높은 모수를 추정하는 방법

- 베이즈 정리



## CNN

- Convolution 연산을 활용, 커널을 입력벡터 상에서 움직여가면서 선형모델과 합성함수가 적용된다.



## RNN

- 이전 시퀸스의 정보를 가지고 앞으로 발생할 데이터의 확률분포를 다루기 위해 조건부 확률을 이용한다.

- BPTT - RNN의 역전파 방법

# 느낀 점🤔

수학이 너무 어렵다. 수식이 어려운건 기본이고 이론을 이해하기가 조금 어려웠다. 

일단, 수식이 이해가 안되더라도 수식이 익숙해질 때까지 계속 살펴봐야겠다.

\+ MLE, BPTT 공부하자
